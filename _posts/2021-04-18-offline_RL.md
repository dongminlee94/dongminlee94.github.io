---
title: "Papers on Offline Reinforcement Learning"
toc: true
toc_sticky: true
categories:
  - RL
---

<center> <img src='../../assets/images/offline_rl.png' width="550"> </center>

## An Optimistic Perspective on Offline Reinforcement Learning (2019.07)

- Author: Rishabh Agarwal, Dale Schuurmans, Mohammad Norouzi
- Proceeding: International Conference on Machine Learning (ICML) 2020
- [[PDF](https://arxiv.org/pdf/1907.04543.pdf)][[Website](https://offline-rl.github.io/)][[arXiv](https://arxiv.org/abs/1907.04543)]

---

## D4RL: Datasets for Deep Data-Driven Reinforcement Learning (2020.04)

- Author: Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, Sergey Levine
- Proceeding: arXiv preprint 2020
- [[PDF](https://arxiv.org/pdf/2004.07219.pdf)][[Website](https://sites.google.com/view/d4rl/home)][[arXiv](https://arxiv.org/abs/2004.07219)]

---

## Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems (2020.05)

- Author: Sergey Levine, Aviral Kumar, George Tucker, Justin Fu
- Proceeding: International Conference on Robotics and Automation (ICRA) 2021
- [[PDF](https://arxiv.org/pdf/2005.01643.pdf)][[arXiv](https://arxiv.org/abs/2005.01643)]

---

## MOPO: Model-based Offline Policy Optimization (2020.05)

- Author: Tianhe Yu, Garrett Thomas, Lantao Yu, Stefano Ermon, James Zou, Sergey Levine, Chelsea Finn, Tengyu Ma
- Proceeding: Conference on Neural Information Processing Systems (NeurIPS) 2020
- [[PDF](https://arxiv.org/pdf/2005.13239.pdf)][[arXiv](https://arxiv.org/abs/2005.13239)][[Video](https://www.youtube.com/watch?v=hTwsxSd0AxU)]

---

## Accelerating Online Reinforcement Learning with Offline Datasets (2020.06)

- Author: Ashvin Nair, Murtaza Dalal, Abhishek Gupta, Sergey Levine
- Proceeding: arXiv preprint 2020
- [[PDF](https://arxiv.org/pdf/2006.09359.pdf)][[Website](https://awacrl.github.io/)][[arXiv](https://arxiv.org/abs/2006.09359)]

---

## Conservative Q-Learning for Offline Reinforcement Learning (2020.06)

- Author: Aviral Kumar, Aurick Zhou, George Tucker, Sergey Levine
- Proceeding: Conference on Neural Information Processing Systems (NeurIPS) 2020
- [[PDF](https://proceedings.neurips.cc//paper/2020/file/0d2b2061826a5df3221116a5085a6052-Paper.pdf)][[Website](https://sites.google.com/view/cql-offline-rl)][[arXiv](https://arxiv.org/abs/2006.04779)]

---

## RL Unplugged: A Suite of Benchmarks for Offline Reinforcement Learning (2020.06)

- Author: Caglar Gulcehre, Ziyu Wang, Alexander Novikov, Tom Le Paine, Sergio Gomez Colmenarejo, Konrad Zolna, Rishabh Agarwal, Josh Merel, Daniel Mankowitz, Cosmin Paduraru, Gabriel Dulac-Arnold, Jerry Li, Mohammad Norouzi, Matt Hoffman, Ofir Nachum, George Tucker, Nicolas Heess, Nando de Freitas
- Proceeding: Conference on Neural Information Processing Systems (NeurIPS) 2020
- [[PDF](http://128.84.4.34/pdf/2006.13888)][[arXiv](http://128.84.4.34/abs/2006.13888)][[Code](https://github.com/deepmind/deepmind-research/tree/master/rl_unplugged)]

---

## OPAL: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning (2020.10)

- Author: Anurag Ajay, Aviral Kumar, Pulkit Agrawal, Sergey Levine, Ofir Nachum
- Proceeding: International Conference on Learning Representations (ICLR) 2021
- [[PDF](https://openreview.net/pdf?id=V69LGwJ0lIN)][[Website](https://sites.google.com/view/opal-iclr)][[arXiv](https://arxiv.org/abs/2010.13611)]

---

## COG: Connecting New Skills to Past Experience with Offline Reinforcement Learning (2020.10)

- Author: Avi Singh, Albert Yu, Jonathan Yang, Jesse Zhang, Aviral Kumar, Sergey Levine
- Proceeding: Conference on Robot Learning (CoRL) 2020
- [[PDF](https://arxiv.org/pdf/2010.14500.pdf)][[Website](https://sites.google.com/view/cog-rl)][[arXiv](https://arxiv.org/abs/2010.14500)]

---

## Offline Learning from Demonstrations and Unlabeled Experience (2020.11)

- Author: Konrad Zolna, Alexander Novikov, Ksenia Konyushkova, Caglar Gulcehre, Ziyu Wang, Yusuf Aytar, Misha Denil, Nando de Freitas, Scott Reed
- Proceeding: Conference on Neural Information Processing Systems (NeurIPS) Offline Reinforcement Learning Workshop 2020
- [[PDF](https://arxiv.org/pdf/2011.13885.pdf)][[arXiv](https://arxiv.org/abs/2011.13885)]

---

## COMBO: Conservative Offline Model-Based Policy Optimization (2021.02)

- Author: Tianhe Yu, Aviral Kumar, Rafael Rafailov, Aravind Rajeswaran, Sergey Levine, Chelsea Finn
- Proceeding: arXiv preprint 2021
- [[PDF](https://arxiv.org/pdf/2102.08363.pdf)][[arXiv](https://arxiv.org/abs/2102.08363)]

---

## References

- NeurIPS 2020 Tutorial - Offline Reinforcement Learning: From Algorithms to Practical Challenges [[Website](https://sites.google.com/view/offlinerltutorial-neurips2020/home)]
- Seita's Place Blog - Offline (Batch) Reinforcement Learning: A Review of Literature and Applications [[Website](https://danieltakeshi.github.io/2020/06/28/offline-rl/)]
- Tistory Blog - Offline (batch) Reinforcement Learning의 의미와 적용 [[Website](https://talkingaboutme.tistory.com/entry/RL-Offline-Reinforcement-Learning)]
- Sergey Levine YouTube - Offline Reinforcement Learning [[Video](https://www.youtube.com/watch?v=qgZPZREor5I)]
- CS285: Deep Reinforcement Learning - Offline Reinforcement Learning [[PDF](http://rail.eecs.berkeley.edu/deeprlcourse/static/slides/lec-15.pdf)]
- BAIR Blog - Offline Reinforcement Learning: How Conservative Algorithms Can Enable New Applications [[Website](https://bair.berkeley.edu/blog/2020/12/07/offline/)]
